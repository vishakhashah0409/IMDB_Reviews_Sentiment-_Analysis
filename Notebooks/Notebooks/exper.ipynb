{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31bd360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    # to load dataset\n",
    "import numpy as np     # for mathematic equation\n",
    "from nltk.corpus import stopwords   # to get collection of stopwords\n",
    "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
    "from tensorflow.keras.models import Sequential     # the model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
    "from tensorflow.keras.models import load_model   # load saved model\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "008afbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed</th>\n",
       "      <th>word count</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One reviewers mentioned watching 1 Oz episode ...</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production. &lt;br / &gt;&lt;br / &gt;The...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production the filming techni...</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically ' family little boy ( Jake ) thinks ...</td>\n",
       "      <td>0</td>\n",
       "      <td>basically  family little boy  jake  thinks  zo...</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei ' \" Love Time Money \" visually s...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter mattei   love time money  visually stun...</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49577</th>\n",
       "      <td>49995</td>\n",
       "      <td>thought movie right good job. ' creative origi...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought movie right good job  creative origina...</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49578</th>\n",
       "      <td>49996</td>\n",
       "      <td>Bad plot , bad dialogue , bad acting , idiotic...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad plot  bad dialogue  bad acting  idiotic di...</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49579</th>\n",
       "      <td>49997</td>\n",
       "      <td>Catholic taught parochial elementary schools n...</td>\n",
       "      <td>0</td>\n",
       "      <td>catholic taught parochial elementary schools n...</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49580</th>\n",
       "      <td>49998</td>\n",
       "      <td>' going disagree previous comment side Maltin ...</td>\n",
       "      <td>0</td>\n",
       "      <td>going disagree previous comment side maltin o...</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49581</th>\n",
       "      <td>49999</td>\n",
       "      <td>one expects Star Trek movies high art , fans e...</td>\n",
       "      <td>0</td>\n",
       "      <td>one expects star trek movies high art  fans ex...</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49582 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             review  \\\n",
       "0               0  One reviewers mentioned watching 1 Oz episode ...   \n",
       "1               1  wonderful little production. <br / ><br / >The...   \n",
       "2               2  thought wonderful way spend time hot summer we...   \n",
       "3               3  Basically ' family little boy ( Jake ) thinks ...   \n",
       "4               4  Petter Mattei ' \" Love Time Money \" visually s...   \n",
       "...           ...                                                ...   \n",
       "49577       49995  thought movie right good job. ' creative origi...   \n",
       "49578       49996  Bad plot , bad dialogue , bad acting , idiotic...   \n",
       "49579       49997  Catholic taught parochial elementary schools n...   \n",
       "49580       49998  ' going disagree previous comment side Maltin ...   \n",
       "49581       49999  one expects Star Trek movies high art , fans e...   \n",
       "\n",
       "       sentiment                                          processed  \\\n",
       "0              1  one reviewers mentioned watching 1 oz episode ...   \n",
       "1              1  wonderful little production the filming techni...   \n",
       "2              1  thought wonderful way spend time hot summer we...   \n",
       "3              0  basically  family little boy  jake  thinks  zo...   \n",
       "4              1  petter mattei   love time money  visually stun...   \n",
       "...          ...                                                ...   \n",
       "49577          1  thought movie right good job  creative origina...   \n",
       "49578          0  bad plot  bad dialogue  bad acting  idiotic di...   \n",
       "49579          0  catholic taught parochial elementary schools n...   \n",
       "49580          0   going disagree previous comment side maltin o...   \n",
       "49581          0  one expects star trek movies high art  fans ex...   \n",
       "\n",
       "       word count  length  \n",
       "0             215     215  \n",
       "1             116     116  \n",
       "2             116     116  \n",
       "3              92      92  \n",
       "4             160     160  \n",
       "...           ...     ...  \n",
       "49577         114     114  \n",
       "49578          73      73  \n",
       "49579         142     142  \n",
       "49580         135     135  \n",
       "49581          85      85  \n",
       "\n",
       "[49582 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=pd.read_csv(\"C:/Users/visha/OneDrive/Documents/processeddata.csv\")\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b42202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Preprocessing the data for SVM and Logistic Regression models\n",
    "#tfidf = TfidfVectorizer(max_features=5000)\n",
    "#X = tfidf.fit_transform(data1['processed']).toarray()\n",
    "#y = data1['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47067876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "[[0.22946382 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]] \n",
      "\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.07657825 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]] \n",
      "\n",
      "Test Set\n",
      "7827     0\n",
      "4811     0\n",
      "35252    1\n",
      "3446     0\n",
      "24377    0\n",
      "        ..\n",
      "11284    0\n",
      "44732    0\n",
      "38158    0\n",
      "860      1\n",
      "15795    1\n",
      "Name: sentiment, Length: 39665, dtype: int64 \n",
      "\n",
      "29035    0\n",
      "43282    1\n",
      "38461    0\n",
      "16000    0\n",
      "5245     1\n",
      "        ..\n",
      "2923     1\n",
      "15253    0\n",
      "17792    0\n",
      "37836    0\n",
      "2691     0\n",
      "Name: sentiment, Length: 9917, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Train Set')\n",
    "print(X_train, '\\n')\n",
    "print(X_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f464d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for review in X_train:\n",
    "        review_length.append(len(review))\n",
    "\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "886c09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE SENTIMENT -> 0 & 1\n",
    "x_data = data1['review']       \n",
    "y_data = data1['sentiment'] \n",
    "y_data = y_data.replace('positive', 1)\n",
    "y_data = y_data.replace('negative', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "638945aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "WARNING:tensorflow:The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "max_features = 20000\n",
    "\n",
    "print('Loading data ...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3867ff72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])#Lets take a look on item 0 of this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55f794c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (25000, 80)\n",
      "X_test shape: (25000, 80)\n",
      "Encoded X Train\n",
      " [[   1   14   22 ...    4   22   17]\n",
      " [   1  194 1153 ...    9   45   43]\n",
      " [   1   14   47 ...  278   36   69]\n",
      " ...\n",
      " [   1   11    6 ...  960  108   45]\n",
      " [   1 1446 7079 ...   40    5  421]\n",
      " [   1   17    6 ...  109   29  127]] \n",
      "\n",
      "Encoded X Test\n",
      " [[   1  591  202 ...    0    0    0]\n",
      " [   1   14   22 ...   85  108  131]\n",
      " [   1  111  748 ...   31 2122   33]\n",
      " ...\n",
      " [   1   13 1408 ...    0    0    0]\n",
      " [   1   11  119 ...   12    5   55]\n",
      " [   1    6   52 ...    9  194   21]] \n",
      "\n",
      "Maximum review length:  80\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "maxlen = 80\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen, padding='post', truncating='post')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen, padding='post', truncating='post')\n",
    "max_length = get_max_length()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Encoded X Train\\n', X_train, '\\n')\n",
    "print('Encoded X Test\\n', X_test, '\\n')\n",
    "print('Maximum review length: ', max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07ed648c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,   14,   22, ...,    4,   22,   17],\n",
       "       [   1,  194, 1153, ...,    9,   45,   43],\n",
       "       [   1,   14,   47, ...,  278,   36,   69],\n",
       "       ...,\n",
       "       [   1,   11,    6, ...,  960,  108,   45],\n",
       "       [   1, 1446, 7079, ...,   40,    5,  421],\n",
       "       [   1,   17,    6, ...,  109,   29,  127]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a8b1354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "    print (len(X_train[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b115cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2)) # 128 = dimensionality of the output space\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c91c97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'models/LSTM.h5',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9d0e855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/3\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.5157 - accuracy: 0.7291\n",
      "Epoch 1: accuracy improved from -inf to 0.72908, saving model to models\\LSTM.h5\n",
      "125/125 [==============================] - 223s 2s/step - loss: 0.5157 - accuracy: 0.7291 - val_loss: 0.4322 - val_accuracy: 0.8000\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.8772\n",
      "Epoch 2: accuracy improved from 0.72908 to 0.87716, saving model to models\\LSTM.h5\n",
      "125/125 [==============================] - 100s 804ms/step - loss: 0.3066 - accuracy: 0.8772 - val_loss: 0.4438 - val_accuracy: 0.7937\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.9184\n",
      "Epoch 3: accuracy improved from 0.87716 to 0.91840, saving model to models\\LSTM.h5\n",
      "125/125 [==============================] - 109s 871ms/step - loss: 0.2182 - accuracy: 0.9184 - val_loss: 0.5163 - val_accuracy: 0.7844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x288d7de9f70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=200,\n",
    "          epochs=3,\n",
    "          validation_data=(X_test, y_test),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80cdbae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 11s 92ms/step - loss: 0.5163 - accuracy: 0.7844\n",
      "Test score: 0.516304075717926\n",
      "Test accuracy: 0.7843999862670898\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test, batch_size=200)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "411dc898",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24016/3509264804.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test, batch_size = 128)\n",
    "\n",
    "true = 0\n",
    "for i, y in enumerate(y_test):\n",
    "    if y == y_pred[i]:\n",
    "        true += 1\n",
    "\n",
    "print('Correct Prediction: {}'.format(true))\n",
    "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
    "print('Accuracy: {}'.format(true/len(y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db4a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c126610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
